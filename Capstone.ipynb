{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lunar Cycle Influence on Twitter Sentiment and Stock Markets\n",
    "\n",
    "article on lunar cycles & crime: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1444800/\n",
    "\n",
    "project proposal write-up: https://docs.google.com/document/d/1sAl3SyxhI6gLZ1zDEHhtIOfjB0FzofjjM3Bp7CaIBgM/edit#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain Scrub Explore Model iNterpret!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Twitter Data\n",
    "\n",
    "instructions on accessing the Twitter API and performing sentiment analysis: https://www.geeksforgeeks.org/twitter-sentiment-analysis-using-python/\n",
    "\n",
    "this one has more options and discusses removing user handles and more: https://www.analyticsvidhya.com/blog/2018/07/hands-on-sentiment-analysis-dataset-python/\n",
    "\n",
    "lunar phases: https://www.calendar-12.com/moon_phases/2018\n",
    "\n",
    "   - I need to specify that tweets should come from the middle of the day (when stock market is open)\n",
    "       - if this is not fruitful, I can specify a time after sunset for all time zones\n",
    "   - I also need to limit my search to English language\n",
    "   - I need to limit my search to the United States (or even East Coast or NYC/Chicago, depending on size of dataset)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis code below comes from:\n",
    "# https://www.geeksforgeeks.org/twitter-sentiment-analysis-using-python/\n",
    "\n",
    "import re \n",
    "import tweepy \n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob \n",
    "  \n",
    "class TwitterClient(object): \n",
    "    ''' \n",
    "    Generic Twitter Class for sentiment analysis. \n",
    "    '''\n",
    "    def __init__(self): \n",
    "        ''' \n",
    "        Class constructor or initialization method. \n",
    "        '''\n",
    "        # keys and tokens from the Twitter Dev Console \n",
    "        consumer_key = 'XXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "        consumer_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "        access_token = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "        access_token_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "  \n",
    "        # attempt authentication \n",
    "        try: \n",
    "            # create OAuthHandler object \n",
    "            self.auth = OAuthHandler(consumer_key, consumer_secret) \n",
    "            # set access token and secret \n",
    "            self.auth.set_access_token(access_token, access_token_secret) \n",
    "            # create tweepy API object to fetch tweets \n",
    "            self.api = tweepy.API(self.auth) \n",
    "        except: \n",
    "            print(\"Error: Authentication Failed\") \n",
    "  \n",
    "    def clean_tweet(self, tweet): \n",
    "        ''' \n",
    "        Utility function to clean tweet text by removing links and\n",
    "        special characters using simple regex statements. \n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) \n",
    "                                    |(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
    "  \n",
    "    def get_tweet_sentiment(self, tweet): \n",
    "        ''' \n",
    "        Utility function to classify sentiment of passed tweet \n",
    "        using textblob's sentiment method \n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text \n",
    "        analysis = TextBlob(self.clean_tweet(tweet)) \n",
    "        # set sentiment \n",
    "        if analysis.sentiment.polarity > 0: \n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0: \n",
    "            return 'neutral'\n",
    "        else: \n",
    "            return 'negative'\n",
    "  \n",
    "    def get_tweets(self, query, count=1000): \n",
    "        ''' \n",
    "        Main function to fetch tweets and parse them. \n",
    "        '''\n",
    "        # empty list to store parsed tweets \n",
    "        tweets = [] \n",
    "  \n",
    "        try: \n",
    "            # call twitter api to fetch tweets \n",
    "            fetched_tweets = self.api.search(q = query, count = count) \n",
    "  \n",
    "            # parsing tweets one by one \n",
    "            for tweet in fetched_tweets: \n",
    "                # empty dictionary to store required params of a tweet \n",
    "                parsed_tweet = {} \n",
    "  \n",
    "                # saving text of tweet \n",
    "                parsed_tweet['text'] = tweet.text \n",
    "                # saving sentiment of tweet \n",
    "                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text) \n",
    "  \n",
    "                # appending parsed tweet to tweets list \n",
    "                if tweet.retweet_count > 0: \n",
    "                    # if tweet has retweets, ensure that it is appended only once \n",
    "                    if parsed_tweet not in tweets: \n",
    "                        tweets.append(parsed_tweet) \n",
    "                else: \n",
    "                    tweets.append(parsed_tweet) \n",
    "  \n",
    "            # return parsed tweets \n",
    "            return tweets \n",
    "  \n",
    "        except tweepy.TweepError as e: \n",
    "            # print error (if any) \n",
    "            print(\"Error : \" + str(e)) \n",
    "  \n",
    "def main(query, count=1000): \n",
    "    # creating object of TwitterClient Class \n",
    "    api = TwitterClient() \n",
    "    # calling function to get tweets \n",
    "    tweets = api.get_tweets(query = query, count = count) \n",
    "  \n",
    "    # picking positive tweets from tweets \n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive'] \n",
    "    # percentage of positive tweets \n",
    "    print(f\"Positive tweets percentage: {100*len(ptweets)/len(tweets)} %\") \n",
    "    # picking negative tweets from tweets \n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
    "    # percentage of negative tweets \n",
    "    print(f\"Negative tweets percentage: {100*len(ntweets)/len(tweets)} %\") \n",
    "    # percentage of neutral tweets \n",
    "    print(f\"Neutral tweets percentage: {100*len(tweets - ntweets - ptweets)/len(tweets)} %\") \n",
    "  \n",
    "    # printing first 5 positive tweets \n",
    "    print(\"\\n\\nPositive tweets:\") \n",
    "    for tweet in ptweets[:10]: \n",
    "        print(tweet['text']) \n",
    "  \n",
    "    # printing first 5 negative tweets \n",
    "    print(\"\\n\\nNegative tweets:\") \n",
    "    for tweet in ntweets[:10]: \n",
    "        print(tweet['text']) \n",
    "  \n",
    "# if __name__ == \"__main__\": \n",
    "#     # calling main function \n",
    "#     main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Financial Data\n",
    "\n",
    "website to get historical infra-day stock prices: https://www.alphavantage.co/documentation/\n",
    "   - request limitations: 5/minute, 500/day\n",
    "   - URL structure: https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=MSFT&outputsize=full&apikey=demo\n",
    "   - (back up option: https://docs.intrinio.com/tutorial/web_api)\n",
    "   \n",
    "I need to be careful about how I look at this data. Since stock markets are only open 6.5 hours a day, 5 days a week, certain lunar cycle days will fall on weekends, while considerable after-hours trading can affect next-day opening prices. Since lunar cycles are most noticeble at night, I should probably set stock days as 24-hour periods, from opening bell to following opening bell to account for evening trading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOW DO I HIDE my API keys from the public and still use the code???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering the Stock Symbol and API key\n",
    "symbol = 'MSFT'\n",
    "stocks_API_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making an API request for a certain stock's hsitory\n",
    "credentials = {'function':'TIME_SERIES_DAILY', 'symbol':symbol, 'outputsize':'full', 'apikey':stocks_API_key}\n",
    "r = requests.get('https://www.alphavantage.co/query', params=credentials)\n",
    "print(r.status_code)\n",
    "r.status_code == requests.codes.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>136.9500</td>\n",
       "      <td>137.4900</td>\n",
       "      <td>136.4250</td>\n",
       "      <td>136.9000</td>\n",
       "      <td>6552343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-16</td>\n",
       "      <td>135.8300</td>\n",
       "      <td>136.7000</td>\n",
       "      <td>135.6600</td>\n",
       "      <td>136.3300</td>\n",
       "      <td>14785072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-13</td>\n",
       "      <td>137.7800</td>\n",
       "      <td>138.0600</td>\n",
       "      <td>136.5700</td>\n",
       "      <td>137.3200</td>\n",
       "      <td>22902300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-12</td>\n",
       "      <td>137.8500</td>\n",
       "      <td>138.4200</td>\n",
       "      <td>136.8700</td>\n",
       "      <td>137.5200</td>\n",
       "      <td>27010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-09-11</td>\n",
       "      <td>135.9100</td>\n",
       "      <td>136.2700</td>\n",
       "      <td>135.0900</td>\n",
       "      <td>136.1200</td>\n",
       "      <td>24726100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index   1. open   2. high    3. low  4. close 5. volume\n",
       "0  2019-09-17  136.9500  137.4900  136.4250  136.9000   6552343\n",
       "1  2019-09-16  135.8300  136.7000  135.6600  136.3300  14785072\n",
       "2  2019-09-13  137.7800  138.0600  136.5700  137.3200  22902300\n",
       "3  2019-09-12  137.8500  138.4200  136.8700  137.5200  27010000\n",
       "4  2019-09-11  135.9100  136.2700  135.0900  136.1200  24726100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stock_df = pd.DataFrame(r.text)\n",
    "df = pd.DataFrame(r.json()[\"Time Series (Daily)\"])\n",
    "df = df.T.reset_index()\n",
    "df.columns = ['date','open','high','low','close','volume']\n",
    "df.date = pd.to_datetime(df.date)\n",
    "df[['open','high','low','close','volume']] = df[['open','high','low','close','volume']].astype(float)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining List of Dates of 2018 Lunar Phases\n",
    "\n",
    "file is stored as `lunar_phases_2018.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Full Moon</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Mon</td>\n",
       "      <td>20:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Last Quarter</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>Mon</td>\n",
       "      <td>16:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Moon</td>\n",
       "      <td>2018-01-16</td>\n",
       "      <td>Tue</td>\n",
       "      <td>20:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First Quarter</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>Wed</td>\n",
       "      <td>16:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Full Moon</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>Wed</td>\n",
       "      <td>7:27:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           phase       date weekday      time\n",
       "0      Full Moon 2018-01-01     Mon  20:25:00\n",
       "1   Last Quarter 2018-01-08     Mon  16:26:00\n",
       "2       New Moon 2018-01-16     Tue  20:18:00\n",
       "3  First Quarter 2018-01-24     Wed  16:20:00\n",
       "4      Full Moon 2018-01-31     Wed   7:27:00"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading in a list of 2018 lunar phases\n",
    "phases_2018 = pd.read_csv('lunar_phases_2018.csv')\n",
    "phases_2018.date = pd.to_datetime(phases_2018.date)\n",
    "phases_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
